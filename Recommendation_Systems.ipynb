{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df287KEkVXra",
        "outputId": "19ebe8ce-6831-4705-f0ef-740c4a3297a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.37.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.4.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Collecting tenacity<9,>=8.1.0 (from streamlit)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl.metadata (38 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.37.1-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: watchdog, tenacity, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.37.1 tenacity-8.5.0 watchdog-4.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRJL6ANIW5Ej"
      },
      "source": [
        "## **STREAMLIT APPLICATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hQHNaN3oaI0",
        "outputId": "d9f8fa29-b9ce-469e-aaee-f818bddb8b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kV8m5JGZLCE",
        "outputId": "bc2130b3-85db-4a27-a893-61515ed6e0a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import streamlit as st\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "#st.set_option('deprecation.showPyplotGlobalUse', False) #do not show warning when plotting on streamlit\n",
        "\n",
        "# Title and description of the Streamlit app\n",
        "st.title(\"GAME RECOMMENDATION SYSTEM\")\n",
        "st.subheader(\"ABOUT PROJECT\")\n",
        "st.write(\"Welcome to Game Recommendation System! This project utilizes the Steam Game Dataset sourced from Kaggle to provide personalized game suggestions. Three methods for training the model has been implemented in this project:\")\n",
        "st.write(\"1. Leveraging scikit-learn's Nearest Neighbour library for efficient recommendation based on game features.\")\n",
        "st.write(\"2. Developing a custom Nearest Neighbour algorithm from scratch, ensuring a deeper understanding of recommendation processes.\")\n",
        "st.write(\"3. Implementing a user-personalized model that tracks individual search histories, enhancing recommendation accuracy over time.\")\n",
        "\n",
        "# Reading datasets\n",
        "data=pd.read_csv(\"/content/games.csv\")\n",
        "meta_data=pd.read_json(\"games_metadata.json\",lines=True)\n",
        "\n",
        "st.subheader(\"EXPLORATORY DATA ANALYSIS\")\n",
        "# Merging datasets\n",
        "merge_data=data.merge(meta_data,on=\"app_id\")\n",
        "\n",
        "\n",
        "# Filtering out games with less reviews\n",
        "filter_=merge_data[merge_data['user_reviews']<500]\n",
        "merge_data.drop(filter_.index,inplace=True)\n",
        "\n",
        "# Cleaning data that do not have any description\n",
        "filter_data=merge_data[merge_data[\"description\"]==\"\"]\n",
        "merge_data=merge_data.drop(filter_data.index)\n",
        "merge_data.reset_index(drop=True,inplace=True)\n",
        "\n",
        "# Function to convert three OS columns into a single column\n",
        "\n",
        "def OS_column(row):\n",
        "  array = np.array([\"win\", \"mac\", \"linux\"])\n",
        "  filter=row['win':'linux'].values.astype(bool)\n",
        "  return array[filter].tolist()\n",
        "\n",
        "# converting three columns into a single column of OS\n",
        "merge_data[\"OS\"]=merge_data.apply(lambda row:OS_column(row),axis=1)\n",
        "# Splitting description into a list of words\n",
        "merge_data['description']=merge_data['description'].apply(lambda x:x.split())\n",
        "\n",
        "# Removing spaces between words in tags\n",
        "merge_data[\"tags\"]=merge_data[\"tags\"].apply(lambda x:[i.replace(\" \",\"\") for i in x])\n",
        "\n",
        "# Renaming column tags to keywords\n",
        "merge_data.rename(columns={\"tags\":\"keywords\"},inplace=True)\n",
        "\n",
        "# Combining description, keywords, and OS columns into tags column\n",
        "\n",
        "merge_data['tags']=merge_data['description']+merge_data['keywords']+merge_data['OS']\n",
        "\n",
        "merge_data['tags']=merge_data[\"tags\"].apply(lambda x:[i.lower() for i in x])\n",
        "merge_data.reset_index(drop=True,inplace=True)\n",
        "new_df=merge_data[[\"app_id\",\"title\",\"tags\"]].copy()\n",
        "new_df['tags']=new_df['tags'].apply(lambda x:\" \".join(x))\n",
        "\n",
        "#functions for exploratory data analysis\n",
        "\n",
        "# Function to visualize game distribution\n",
        "\n",
        "def game_distribution():\n",
        "\n",
        "      fig, ax=plt.subplots(1,2,figsize=(20,10))\n",
        "      merge_data.groupby('rating').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'),ax=ax[0])\n",
        "      ax[0].set_ylabel(\"Rating\",fontsize=15)\n",
        "      ax[1].pie(merge_data['rating'].value_counts().tolist(),autopct='%1.1f%%',\n",
        "          labels=merge_data['rating'].value_counts().keys(),\n",
        "          wedgeprops={'edgecolor': 'black', 'linewidth': 0.5, 'width': 1})\n",
        "\n",
        "      fig.suptitle(\"Game Distribution Overview\", fontsize=20, y=1.02)\n",
        "\n",
        "\n",
        "      st.pyplot()\n",
        "\n",
        "\n",
        "# Function to visualize game reviews\n",
        "def game_reviews():\n",
        "\n",
        "      plt.figure(figsize=(15,10))\n",
        "      sns.barplot(x='title',y='user_reviews',\n",
        "                  data=merge_data[[\"title\",'rating','user_reviews','positive_ratio']].\n",
        "                  sort_values(by='user_reviews',ascending=False).head(35),\n",
        "                  hue='rating',)\n",
        "      plt.tick_params(axis='x',rotation=90,width=5)\n",
        "      plt.xlabel(\"Game Titles\",fontsize=10)\n",
        "      plt.ylabel(\"No of Reviews\",fontsize=10)\n",
        "      plt.title(\"Top 30 User Reviewed Games\",fontsize=16)\n",
        "      st.pyplot()\n",
        "\n",
        "\n",
        "# Function to visualize game prices\n",
        "\n",
        "def game_price():\n",
        "        plt.figure(figsize=(15,10))\n",
        "        sns.barplot(x='title',y='price_final',data=merge_data[[\"title\",'rating','price_final']].query('price_final>60').\n",
        "                    sort_values(by='price_final',ascending=False),hue='rating')\n",
        "        plt.tick_params(axis='x',rotation=90,width=5)\n",
        "        plt.xlabel(\"Titles\",fontsize=12)\n",
        "        plt.ylabel(\"Price($)\",fontsize=12)\n",
        "        plt.title(\" Most Expensive Games and Softwares\",fontsize=16)\n",
        "        st.pyplot()\n",
        "\n",
        "# Function to visualize low-rated games\n",
        "\n",
        "def low_rated():\n",
        "\n",
        "        plt.figure(figsize=(20,10))\n",
        "        sns.barplot(x='title',y='positive_ratio',\n",
        "                    data=merge_data[['title','positive_ratio','rating']].\n",
        "                    sort_values(by='positive_ratio',ascending=True).head(10),hue='rating',palette=\"magma\")\n",
        "        plt.tick_params(axis='x',rotation=90,width=15)\n",
        "        plt.xlabel(\"Titles\",fontsize=10)\n",
        "        plt.ylabel(\"Positivity Ratio\",fontsize=10)\n",
        "        plt.title(\"Top 10 Low Rated Games\",fontsize=16)\n",
        "        st.pyplot()\n",
        "\n",
        "# Create a dropdown to select the plot\n",
        "selected_plot = st.selectbox('Select Plot', ['Distribution of Games', 'Game Reviews', 'Most Expensive Games', 'Low Rated Games'])\n",
        "plot_button = st.button('Plot')\n",
        "\n",
        "if plot_button:\n",
        "        if selected_plot == 'Distribution of Games':\n",
        "              game_distribution()\n",
        "        elif selected_plot == 'Game Reviews':\n",
        "              game_reviews()\n",
        "        elif selected_plot == 'Most Expensive Games':\n",
        "              game_price()\n",
        "        elif selected_plot == 'Low Rated Games':\n",
        "              low_rated()\n",
        "st.subheader(\"Top Rated Games List\")\n",
        "table_button=st.button(\"Show\")\n",
        "\n",
        "if table_button:\n",
        "\n",
        "  top_games=merge_data[['title','positive_ratio','user_reviews']].query('positive_ratio>80 and user_reviews>80000 ').sort_values(by='positive_ratio',ascending=False).copy()\n",
        "  top_games.reset_index(drop=True,inplace=True)\n",
        "  top_games.rename(columns={\"title\":\"Game Title\",\"positive_ratio\":\"Positive Ratio\",\"user_reviews\":\"No of Reviews\"},inplace=True)\n",
        "  st.table(top_games)\n",
        "\n",
        "#initializing stemming which is the process of reducing words to their word stem, base, or root form.\n",
        "\n",
        "ps=PorterStemmer()\n",
        "\n",
        "\n",
        "def stemming(text):\n",
        "    words = nltk.word_tokenize(text)  # make a list words from the given text.\n",
        "    stemmed_words = [ps.stem(word) for word in words] #apply stemming\n",
        "    return \" \".join(stemmed_words) #rejoing words after stemming\n",
        "\n",
        "\n",
        "# Caching the expensive computation using Streamlit cache\n",
        "\n",
        "@st.cache_data(ttl=3600)\n",
        "def expensive_computation():\n",
        "\n",
        "      new_df['tags']=new_df['tags'].apply(stemming)\n",
        "\n",
        "      cv=CountVectorizer(max_features=6000,stop_words=\"english\")\n",
        "\n",
        "      vector=cv.fit_transform(new_df[\"tags\"]).toarray()\n",
        "\n",
        "      similarity=cosine_similarity(vector)\n",
        "\n",
        "      return vector,similarity\n",
        "\n",
        "\n",
        "# Fetching vector and similarity using Streamlit cache\n",
        "\n",
        "vector,similarity=expensive_computation()\n",
        "\n",
        "\n",
        "\n",
        "# Recommender functions\n",
        "\n",
        "\n",
        "# Recommender based on cosine similarity\n",
        "def recommender(game):\n",
        "  game_list=sorted(list(enumerate(similarity[new_df[new_df['title']==game]\n",
        "                                              .index[0]])),reverse=True,\n",
        "                                               key=lambda x:x[1] )[1:5]\n",
        "  recommendation=[(new_df.iloc[i[0]][\"title\"],new_df.iloc[i[0]][\"app_id\"]) for i in game_list]\n",
        "  return recommendation\n",
        "\n",
        "\n",
        "# Recommender using Nearest Neighbors\n",
        "\n",
        "model_nn = NearestNeighbors(n_neighbors=5, metric='cosine', algorithm='brute')\n",
        "\n",
        "model_nn.fit(vector)\n",
        "\n",
        "def nn_recommender(game_):\n",
        "  distances,indices=model_nn.kneighbors(vector[new_df.query('title==@game_').index[0]].reshape(1,-1))\n",
        "  recommender_=[(new_df.iloc[i][\"title\"],new_df.iloc[i][\"app_id\"]) for i in indices[:,1:].reshape(4,)]\n",
        "  return recommender_\n",
        "\n",
        "\n",
        "# Recommender based on user preferences\n",
        "\n",
        "def Preffered_recommendation(game_list):\n",
        "\n",
        "  user_vector=np.zeros(6000)\n",
        "  game_vector=[]\n",
        "  index_vector=[]\n",
        "  result_tuple=[]\n",
        "  x=list(enumerate(vector))\n",
        "\n",
        "  for i in range(len(game_list)):\n",
        "    index_value=new_df[new_df['title']==game_list[i]].index[0]\n",
        "    user_vector+=x[index_value][1]\n",
        "    y=sorted(list(enumerate(similarity[index_value])),reverse=True,key=lambda x:x[1] )[1:11]\n",
        "    for values in y:\n",
        "        game_vector.append(x[values[0]][1])\n",
        "        index_vector.append(values[0])\n",
        "\n",
        "\n",
        "\n",
        "  final_user_vector=user_vector/len(game_list)\n",
        "  answer=np.dot(np.array(final_user_vector),np.array(game_vector).T)\n",
        "\n",
        "  result_tuple = sorted(list(zip(index_vector, answer)),reverse=True,key=lambda x:x[1])[:6]\n",
        "\n",
        "  recommendation=[(new_df.iloc[j[0]][\"title\"],new_df.iloc[j[0]][\"app_id\"]) for j in result_tuple]\n",
        "  return recommendation\n",
        "\n",
        "\n",
        "\n",
        "# Function to get game header image from Steam API\n",
        "\n",
        "def get_game_header_image(app_id):\n",
        "    url = f\"https://store.steampowered.com/api/appdetails?appids={app_id}\"\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        if str(app_id) in data:\n",
        "            game_data = data[str(app_id)]\n",
        "            if \"data\" in game_data:\n",
        "                game_info = game_data[\"data\"]\n",
        "                if \"header_image\" in game_info:\n",
        "                    return game_info[\"header_image\"]\n",
        "\n",
        "    return \"NA\"  # Return \"NA\" if header image URL not found\n",
        "\n",
        "\n",
        "# Session state to store searched games\n",
        "\n",
        "if 'games_list' not in st.session_state:\n",
        "    st.session_state.games_list = []\n",
        "\n",
        "def display_game(recommendation_fetched,num_columns):\n",
        "    i=0\n",
        "    columns = st.columns(num_columns)\n",
        "    for game in recommendation_fetched:\n",
        "                image_url = get_game_header_image(game[1])\n",
        "                with columns[i]:\n",
        "                    if image_url != \"NA\":\n",
        "                      response = requests.get(image_url)\n",
        "                      if response.status_code == 200:\n",
        "                          img = Image.open(BytesIO(response.content))\n",
        "                          st.image(img, caption=game[0], use_column_width=True)\n",
        "                      else:\n",
        "                          st.write(\"Unable to fetch image for\", game[0])\n",
        "                    else:\n",
        "                        st.write(game[0])\n",
        "                i+=1\n",
        "\n",
        "\n",
        "st.subheader(\"Recommender\")\n",
        "\n",
        "\n",
        "game_name = st.selectbox(\"Select a game\", new_df['title'])\n",
        "\n",
        "\n",
        "\n",
        "if st.button(\"Search\"):\n",
        "    if game_name:\n",
        "        st.session_state.games_list.append(game_name)\n",
        "\n",
        "        st.markdown(\"**Searched Games:**\")\n",
        "        for game1 in st.session_state.games_list:\n",
        "            st.write(game1)\n",
        "\n",
        "\n",
        "        st.markdown(\"**Recommended Games**\")\n",
        "\n",
        "        recommendations_1 = recommender(game_name)\n",
        "        recommendations_2 = nn_recommender(game_name)\n",
        "        recommendations_3 = Preffered_recommendation(st.session_state.games_list)\n",
        "\n",
        "        # Display images and titles for Nearest Neighbors recommendations\n",
        "        st.subheader(\"Unsupervised Nearest Neighbors Algorithm\")\n",
        "\n",
        "        display_game(recommendations_2,4)\n",
        "\n",
        "\n",
        "\n",
        "        # Display images and titles for Similarity Based recommendations\n",
        "\n",
        "        st.subheader(\"Similarity Based Recommendation\")\n",
        "        display_game(recommendations_1,4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Display images and titles for User Personalized Algorithm recommendations\n",
        "        st.subheader(\"User Personalized Algorithm\")\n",
        "\n",
        "        display_game(recommendations_3,6)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wASGPkS9BHQC"
      },
      "source": [
        "**RUN STREAMLIT APPLICATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtUaUa_3BHQD",
        "outputId": "a46c4cf8-eb6c-4967-f51f-1ee9b5755e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.171.173.109\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m9IRS7paEzx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4697023-dc51-4dd2-c3c8-5e4fc43dfff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.171.173.109:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "  localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20Gy\n",
            "\u001b[K\u001b[?25hyour url is: https://lucky-otters-check.loca.lt\n",
            "2024-08-11 15:27:10.404 \n",
            "Calling `st.pyplot()` without providing a figure argument has been deprecated\n",
            "and will be removed in a later version as it requires the use of Matplotlib's\n",
            "global figure object, which is not thread-safe.\n",
            "\n",
            "To future-proof this code, you should pass in a figure as shown below:\n",
            "\n",
            "```python\n",
            "fig, ax = plt.subplots()\n",
            "ax.scatter([1, 2, 3], [1, 2, 3])\n",
            "# other plotting actions...\n",
            "st.pyplot(fig)\n",
            "```\n",
            "\n",
            "If you have a specific use case that requires this functionality, please let us\n",
            "know via [issue on Github](https://github.com/streamlit/streamlit/issues).\n",
            "\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "! streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oe33NGr8CxjR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}